{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3780b11c-b639-45a8-bad8-b75e26e4c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, UpSampling2D, Activation, Concatenate\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6de605e3-c4b0-4b17-a4eb-8f1dd52650ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Configuration\n",
    "CONFIG = {\n",
    "    \"input_shape\": (1024, 1024),  # Input image shape (height, width)\n",
    "    \"model_path\": \"U-net_model1.h5\",  # Path to save/load the model\n",
    "    \"image_path\": \"loli.png\",  # Path to the input image\n",
    "    \"num_classes\": 2,  # Number of segmentation classes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "254f296c-8b22-4cac-a1ef-5f929aae2e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define Encoder Block\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input_tensor)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    p = MaxPooling2D((2, 2))(x)\n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "790539e3-1fe3-4891-950c-df437aa07563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define Decoder Block\n",
    "def decoder_block(input_tensor, skip_tensor, num_filters):\n",
    "    x = UpSampling2D((2, 2))(input_tensor)\n",
    "    x = Conv2D(num_filters, 2, padding=\"same\")(x)\n",
    "    x = Concatenate()([x, skip_tensor])\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba88017c-7728-4cac-ba70-da1682f9f657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Define U-Net Model\n",
    "def unet_model(input_shape=(256, 256, 3), num_classes=2):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Contracting Path (Encoder)\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "    s5, p5 = encoder_block(p4, 1024)\n",
    "\n",
    "    # Bottleneck\n",
    "    b1 = Conv2D(2048, 3, padding=\"same\")(p5)\n",
    "    b1 = Activation(\"relu\")(b1)\n",
    "    b1 = Conv2D(2048, 3, padding=\"same\")(b1)\n",
    "    b1 = Activation(\"relu\")(b1)\n",
    "\n",
    "    # Expansive Path (Decoder)\n",
    "    d0 = decoder_block(b1, s5, 1024)\n",
    "    d1 = decoder_block(d0, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    # Output Layer\n",
    "    outputs = Conv2D(num_classes, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"U-Net\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c89aa234-91ad-44de-afe1-ef83ee4e19f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6: Load or Train U-Net Model\n",
    "def load_or_train_unet(model_path, input_shape, num_classes):\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Loading pre-trained U-Net model...\")\n",
    "        model = load_model(model_path)\n",
    "    else:\n",
    "        print(\"Training U-Net model...\")\n",
    "        model = unet_model(input_shape=input_shape.__add__((3,)), num_classes=num_classes)\n",
    "        model.save(model_path)\n",
    "        print(\"U-Net model saved.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6cfdcaf8-6c3b-42e9-bf73-13ba920c4adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Preprocess Image\n",
    "def preprocess_image(img_path, input_shape):\n",
    "    img = Image.open(img_path).resize(input_shape)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array[:, :, :3], axis=0) / 255.0\n",
    "    return img, img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4fbf7661-9202-4372-b15f-7e0747eba4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Post-process Prediction\n",
    "def postprocess_prediction(pred, original_img):\n",
    "    pred = np.squeeze(pred, axis=0)  # Remove batch dimension\n",
    "    pred = np.argmax(pred, axis=-1)  # If num_classes > 1, remove channel dimension\n",
    "    pred_img = Image.fromarray(np.uint8(pred * 255))  # Convert to grayscale image  \n",
    "    pred_img = pred_img.resize((original_img.width, original_img.height))  # Resize back to original dimensions\n",
    "    return pred_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12156d4f-40e6-48ea-8b55-c4ade825ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9: Visualization\n",
    "def visualize_prediction(pred_img):\n",
    "    plt.imshow(pred_img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e1ed03a-c54b-45c7-b797-45b9570d30eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training U-Net model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'unet_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     visualize_prediction(pred_img)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[71], line 3\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_or_train_unet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_shape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_classes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     img, img_array \u001b[38;5;241m=\u001b[39m preprocess_image(CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m\"\u001b[39m], CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      5\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(img_array)\n",
      "Cell \u001b[1;32mIn[61], line 8\u001b[0m, in \u001b[0;36mload_or_train_unet\u001b[1;34m(model_path, input_shape, num_classes)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining U-Net model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43munet_model\u001b[49m(input_shape\u001b[38;5;241m=\u001b[39minput_shape\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__add__\u001b[39m((\u001b[38;5;241m3\u001b[39m,)), num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\n\u001b[0;32m      9\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(model_path)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mU-Net model saved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unet_model' is not defined"
     ]
    }
   ],
   "source": [
    "#Step 10: Main Workflow\n",
    "def main():\n",
    "    model = load_or_train_unet(CONFIG[\"model_path\"], CONFIG[\"input_shape\"], CONFIG[\"num_classes\"])\n",
    "    img, img_array = preprocess_image(CONFIG[\"image_path\"], CONFIG[\"input_shape\"])\n",
    "    pred = model.predict(img_array)\n",
    "    pred_img = postprocess_prediction(pred, img)\n",
    "    visualize_prediction(pred_img)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02986788-046c-448e-9ea2-459c67610c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
