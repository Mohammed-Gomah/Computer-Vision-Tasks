{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fb581806-51c7-45e3-8528-55fca0deaa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improt Libraries\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D , MaxPooling2D, Flatten , Dense , Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9b6a1f93-eb2d-4806-8341-8252a2a8fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathes\n",
    "train_dir = r\"F:\\dataset\\task1\\data\\train\"\n",
    "test_dir = r\"F:\\dataset\\task1\\data\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa73172e-c482-4687-ae1b-c8cda61e19d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input shape\n",
    "input_shape = (128,128,3)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b06a9040-cf45-4620-a927-a21140c2d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator\n",
    "data_generator = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e6e275d-b062-4309-bdb2-f8223bf08b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 448 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# train generator and load images \n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (input_shape[0] , input_shape[1]),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e07d561f-ac04-45d4-be7a-d95141616abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# load test images \n",
    "test_generator = data_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (input_shape[0] , input_shape[1]),\n",
    "    batch_size = batch_size,\n",
    "    class_mode= 'categorical',\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4404dbdd-ed11-4412-a0d9-1a55e597837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the  \n",
    "model = Sequential([\n",
    "    Conv2D(32,(3,3),input_shape = input_shape),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(64,(3,3)),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size = (2,2)),\n",
    "    Flatten(),\n",
    "    Dense(64),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ada7fe69-95ee-4f5c-a2a6-fc9f6f0577d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 364ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extract features from train images\n",
    "train_features = model.predict(train_generator)\n",
    "train_feature = train_features.reshape(train_features.shape[0],-1)\n",
    "train_labels = train_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2c59b2a7-a72f-475d-a3f1-e4596495c40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 389ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extract features from test image\n",
    "test_features = model.predict(test_generator)\n",
    "test_featres = test_features.reshape(test_features.shape[0] , -1)\n",
    "test_labels = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2615bdba-96f7-4666-8b52-c855e9aa980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.44%\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the KNN classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = knn_classifier.predict(test_features)\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save the Keras CNN model as an .h5 file\n",
    "model.save('cnn_Feature_Extractor2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b57c75c2-2be4-4139-920f-cf5bfc988b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn_classifier.pkl']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained KNN model\n",
    "joblib.dump(knn_classifier, 'knn_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b39c7-37da-457b-b633-7cbfb90f6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import joblib\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the saved models\n",
    "cnn_model = load_model('cnn_Feature_Extractor2.h5')\n",
    "svm_classifier = joblib.load('svm_classifier.pkl')\n",
    "\n",
    "def classify_image(img_path):\n",
    "    # Load and preprocess the new image\n",
    "    img = image.load_img(img_path, target_size=(128, 128))  # Resize to match the CNN input\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array /= 255.0  # Normalize to match the training preprocessing\n",
    "\n",
    "    # Extract features using the CNN model\n",
    "    features = cnn_model.predict(img_array)\n",
    "    features = features.reshape(1, -1)  # Flatten to 1D for SVM\n",
    "\n",
    "    # Classify the features with the SVM model\n",
    "    prediction = svm_classifier.predict(features)\n",
    "    \n",
    "    # Interpret the prediction\n",
    "    class_labels = {0: 'mask', 1: 'without mask'}  # Adjust based on your dataset labels\n",
    "    result = class_labels[prediction[0]]\n",
    "    return result\n",
    "\n",
    "# Test the function with a new image\n",
    "img_path = 'C:/Users/it shop/Downloads/Dataset/test/without_mask/without_mask_2039.jpg'\n",
    "result = classify_image(img_path)\n",
    "print(f\"The image is classified as: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
